{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"sXVZroZr6McA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732642312793,"user_tz":-60,"elapsed":18593,"user":{"displayName":"Kawtar Elbannoudi","userId":"14690241707666161885"}},"outputId":"ea19e130-4d98-4720-bfc4-859e62bd8fba"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Package 'spoonacular' has an invalid Requires-Python: Invalid specifier: '>=3.*'\u001b[0m\u001b[33m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -qU langgraph langchain langchain-community langchain-groq langchain-core groq neo4j spoonacular"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import json\n","import time\n","from langchain_groq import ChatGroq\n","from langchain_community.graphs import Neo4jGraph\n","from langchain_community.vectorstores import Neo4jVector\n","from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n","from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain.chains import create_retrieval_chain\n","from IPython.display import display, Markdown\n","from typing import Annotated\n","from typing_extensions import TypedDict\n","from IPython.display import Markdown, JSON\n","from langchain_core.output_parsers import JsonOutputParser\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain.schema import Document\n","from langgraph.graph import END, StateGraph\n","import spoonacular as sp"],"metadata":{"id":"Z_OkLzVvUZ9C","executionInfo":{"status":"ok","timestamp":1732642322107,"user_tz":-60,"elapsed":5834,"user":{"displayName":"Kawtar Elbannoudi","userId":"14690241707666161885"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"BapfgcMip-w3"}},{"cell_type":"code","source":["os.environ[\"GROQ_API_KEY\"] = \"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\"\n","os.environ[\"HUGGINGFACE_API_KEY\"] = \"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\"\n","os.environ[\"SPOONACULAR_API_KEY\"] = \"8a39e0add3e041c38c100fa74c99947b\"\n","\n","\n","api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n","\n","NEO4J_URI=\"neo4j+s://09637bc1.databases.neo4j.io\"\n","NEO4J_USERNAME=\"neo4j\"\n","NEO4J_PASSWORD=\"uHqEcVFqFnV3_H3A9QiYRNBBShIlYC-9_xrQeuCkpEk\"\n","NEO4J_DATABASE=\"neo4j\"\n","\n","VECTOR_INDEX_NAME=\"chunk_embeddings\"\n","VECTOR_NODE_LABEL = 'Recipe'\n","VECTOR_SOURCE_PROPERTY = ['name', 'ingredients', 'preparation_method']\n","VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"],"metadata":{"id":"W21vr9r-Xx5v","executionInfo":{"status":"ok","timestamp":1732642325139,"user_tz":-60,"elapsed":225,"user":{"displayName":"Kawtar Elbannoudi","userId":"14690241707666161885"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["llm = ChatGroq(\n","    model=\"llama-3.1-70b-versatile\",\n","    temperature=0,\n","    max_tokens=None,\n","    timeout=None,\n","    max_retries=2,\n",")\n","\n","embeddings = HuggingFaceInferenceAPIEmbeddings(\n","    api_key= api_key, model_name=\"BAAI/bge-small-en-v1.5\"\n",")\n","\n","kg = Neo4jGraph(\n","    url=NEO4J_URI,\n","    username=NEO4J_USERNAME,\n","    password=NEO4J_PASSWORD,\n","    database=NEO4J_DATABASE\n",")"],"metadata":{"id":"9Zym4zY9UlTF","executionInfo":{"status":"ok","timestamp":1732642332872,"user_tz":-60,"elapsed":3149,"user":{"displayName":"Kawtar Elbannoudi","userId":"14690241707666161885"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# web search tool\n","def spoonacular_search(query):\n","  docs=[]\n","  api = sp.API(os.getenv(\"SPOONACULAR_API_KEY\"))\n","\n","  # Step 1: Search for recipes by name\n","  response = api.search_recipes_complex(query=query, number=2)  # Searching for a chocolate cake recipe\n","  data = response.json()\n","\n","  if data.get(\"results\"):\n","    for data in data.get(\"results\"):\n","      result=\"\"\n","      # Step 2: Fetch the first recipe's ID\n","      recipe_id = data[\"id\"]\n","\n","      # Step 3: Get detailed information about the recipe\n","      recipe_response = api.get_recipe_information(recipe_id)\n","      recipe_details = recipe_response.json()\n","\n","      # Step 4: Print recipe instructions and preparation methods\n","      result += \"Recipe Title: \" + recipe_details[\"title\"] + \"\\n\"\n","      result += \"\\nDescription: \" + recipe_details[\"summary\"] + \"\\n\"\n","      result += \"\\nIngredients:\\n\"\n","      for ingredient in recipe_details[\"extendedIngredients\"]:\n","          result += f\"- {ingredient['amount']} {ingredient['unit']} {ingredient['name']}\\n\\n\"\n","\n","      result += \"\\nInstructions:\\n\\n\"\n","      for step in recipe_details[\"analyzedInstructions\"][0][\"steps\"]:\n","          result += f\"Step {step['number']}: {step['step']}\\n\\n\"\n","      docs.append(result)\n","    return docs\n","  else:\n","      return None\n"],"metadata":{"id":"-27xHhg0fgp2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Agentic RAG"],"metadata":{"id":"hSZ6_9dHdgKz"}},{"cell_type":"code","source":["# Retrieval\n","retrieval_query = \"\"\"\n","WITH node, score\n","RETURN node.name AS name, node.description AS description, node.ingredients AS ingredients, node.preparation_method AS preparation_method,\n","    {Name: node.name,Description:node.description,Ingredients: node.ingredients, Preparation:node.preparation_method} AS text,\n","    score,\n","    {score: score} AS metadata\n","\"\"\"\n","\n","neo4j_vector_store = Neo4jVector.from_existing_graph(\n","    embedding=embeddings,\n","    url=NEO4J_URI,\n","    username=NEO4J_USERNAME,\n","    password=NEO4J_PASSWORD,\n","    index_name=VECTOR_INDEX_NAME,\n","    node_label=VECTOR_NODE_LABEL,\n","    text_node_properties=VECTOR_SOURCE_PROPERTY,\n","    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n","    retrieval_query=retrieval_query,\n",")\n","\n","retriever = neo4j_vector_store.as_retriever(\n","    search_type=\"similarity\",\n","    search_kwargs={\"k\": 5}\n",")"],"metadata":{"id":"RU5rX632WCCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retrieval Grader\n","prompt = PromptTemplate(\n","    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance\n","    of a retrieved document to a user question. If the document contains keywords related to the user question,\n","    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n","    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n","    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n","     <|eot_id|><|start_header_id|>user<|end_header_id|>\n","    Here is the retrieved document: \\n\\n {document} \\n\\n\n","    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n","    \"\"\",\n","    input_variables=[\"question\", \"document\"],\n",")\n","\n","retrieval_grader = prompt | llm | JsonOutputParser()"],"metadata":{"id":"pB_kMRiF6VFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Answer question\n","prompt = PromptTemplate(\n","    template=\"\"\"You are an expert chef specializing in finding and creating recipes based on a given context.\n","    Use the following pieces of context to create a recipe. Provide a detailed description of the recipe, including the title, a list of ingredients, and step-by-step instructions.\n","    Keep the recipe clear and precise, suitable for someone to follow and recreate.\n","    Question: {question}\n","    Context: {context}\n","    \"\"\",\n","    input_variables=[\"question\", \"document\"],\n",")\n","# Chain\n","rag_chain = prompt | llm | StrOutputParser()"],"metadata":{"id":"tnk2uAiy5mce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hallucination grader\n","prompt = PromptTemplate(\n","    template=\"\"\"You are a grader assessing whether\n","    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate\n","    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a\n","    single key 'score' and no preamble or explanation.\n","    Here are the facts:\n","    \\n ------- \\n\n","    {documents}\n","    \\n ------- \\n\n","    Here is the answer: {generation}\"\"\",\n","    input_variables=[\"generation\", \"documents\"],\n",")\n","\n","hallucination_grader = prompt | llm | JsonOutputParser()"],"metadata":{"id":"El_hQ95aUdOY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Workflow"],"metadata":{"id":"_7BbXNbAWHX5"}},{"cell_type":"code","source":["from typing_extensions import TypedDict\n","from typing import List\n","\n","### State\n","class GraphState(TypedDict):\n","    question : str\n","    generation : str\n","    web_search : str\n","    documents : List[str]"],"metadata":{"id":"NAnohhq1WMY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def retrieve(state):\n","    \"\"\"\n","    Retrieve documents from vectorstore\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): New key added to state, documents, that contains retrieved documents\n","    \"\"\"\n","    print(\"---RETRIEVE---\")\n","    question = state[\"question\"]\n","\n","    # Retrieval\n","    documents = retriever.invoke(question)\n","    return {\"documents\": documents, \"question\": question}"],"metadata":{"id":"ZM1G1dSIWahB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate(state):\n","    \"\"\"\n","    Generate answer using RAG on retrieved documents\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): New key added to state, generation, that contains LLM generation\n","    \"\"\"\n","    print(\"---GENERATE---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","    # RAG generation\n","    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n","    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n"],"metadata":{"id":"JoDKS8TPVrB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def grade_documents(state):\n","    \"\"\"\n","    Determines whether the retrieved documents are relevant to the question\n","    If any document is not relevant, we will set a flag to run web search\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Filtered out irrelevant documents and updated web_search state\n","    \"\"\"\n","\n","    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Score each doc\n","    filtered_docs = []\n","    web_search = \"No\"\n","    for d in documents:\n","        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n","        grade = score['score']\n","        # Document relevant\n","        if grade.lower() == \"yes\":\n","            print(\"---GRADE: DOCUMENT RELEVANT---\")\n","            filtered_docs.append(d)\n","        # Document not relevant\n","    if len(filtered_docs) == 0:\n","      print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n","      # We do not include the document in filtered_docs\n","      # We set a flag to indicate that we want to run web search\n","      web_search = \"Yes\"\n","    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n"],"metadata":{"id":"V3_OAzGNVq-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def web_search(state):\n","    \"\"\"\n","    Web search based based on the question\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Appended web results to documents\n","    \"\"\"\n","\n","    print(\"---WEB SEARCH---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Web search\n","    docs = spoonacular_search(question)\n","    web_results = \"\\n\".join([d for d in docs])\n","    web_results = Document(page_content=web_results)\n","    if documents is not None:\n","        documents.append(web_results)\n","    else:\n","        documents = [web_results]\n","    return {\"documents\": documents, \"question\": question}"],"metadata":{"id":"e4qCKjGTZwNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decide_to_generate(state):\n","    \"\"\"\n","    Determines whether to generate an answer, or add web search\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        str: Binary decision for next node to call\n","    \"\"\"\n","\n","    print(\"---ASSESS GRADED DOCUMENTS---\")\n","    question = state[\"question\"]\n","    web_search = state[\"web_search\"]\n","    filtered_documents = state[\"documents\"]\n","\n","    if web_search == \"Yes\":\n","        # All documents have been filtered check_relevance\n","        # We will re-generate a new query\n","        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n","        return \"websearch\"\n","    else:\n","        # We have relevant documents, so generate answer\n","        print(\"---DECISION: GENERATE---\")\n","        return \"generate\"\n"],"metadata":{"id":"AsAfsEz-bL9j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def grade_generation_v_documents_and_question(state):\n","    \"\"\"\n","    Determines whether the generation is grounded in the document and answers question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        str: Decision for next node to call\n","    \"\"\"\n","\n","    print(\"---CHECK HALLUCINATIONS---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","    generation = state[\"generation\"]\n","\n","    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n","    grade = score['score']\n","\n","    # Check hallucination\n","    if grade == \"yes\":\n","        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n","        return \"useful\"\n","\n","    else:\n","        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n","        return \"not supported\""],"metadata":{"id":"OZxpT90UbL6B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["workflow = StateGraph(GraphState)\n","\n","workflow.add_node(\"websearch\", web_search)\n","workflow.add_node(\"retrieve\", retrieve)\n","workflow.add_node(\"grade_documents\", grade_documents)\n","workflow.add_node(\"generate\", generate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_BNVg3-dRvU","executionInfo":{"status":"ok","timestamp":1732640459156,"user_tz":-60,"elapsed":271,"user":{"displayName":"Mouad Aoutir","userId":"03235698244910409682"}},"outputId":"e9ea8fde-2189-4415-909e-1de15f692a6b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langgraph.graph.state.StateGraph at 0x7f3c3042ef50>"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["workflow.set_entry_point(\"retrieve\")\n","workflow.add_edge(\"retrieve\", \"grade_documents\")\n","workflow.add_conditional_edges(\n","    \"grade_documents\",\n","    decide_to_generate,\n","    {\n","        \"websearch\": \"websearch\",\n","        \"generate\": \"generate\",\n","    },\n",")\n","workflow.add_edge(\"websearch\", \"generate\")\n","workflow.add_conditional_edges(\n","    \"generate\",\n","    grade_generation_v_documents_and_question,\n","    {\n","        \"useful\": END,\n","        \"not useful\": \"websearch\",\n","    },\n",")"],"metadata":{"id":"9TPpPbpgdRtr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732640459907,"user_tz":-60,"elapsed":4,"user":{"displayName":"Mouad Aoutir","userId":"03235698244910409682"}},"outputId":"6ceb2f0d-fe7f-4a53-ccb9-6765520c6eb3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langgraph.graph.state.StateGraph at 0x7f3c3042ef50>"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["app = workflow.compile()"],"metadata":{"id":"-PFS9GTvINGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pprint import pprint\n","inputs = {\"question\": \"pizza\"}\n","for output in app.stream(inputs):\n","    for key, value in output.items():\n","        pprint(f\"Finished running: {key}:\")\n","Markdown(value[\"generation\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eeGx6Q32IQ6O","executionInfo":{"status":"ok","timestamp":1732640470107,"user_tz":-60,"elapsed":5854,"user":{"displayName":"Mouad Aoutir","userId":"03235698244910409682"}},"outputId":"1b814b3a-7c69-41ac-ac9c-15bd935acab1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---RETRIEVE---\n","'Finished running: retrieve:'\n","---CHECK DOCUMENT RELEVANCE TO QUESTION---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---ASSESS GRADED DOCUMENTS---\n","---DECISION: GENERATE---\n","'Finished running: grade_documents:'\n","---GENERATE---\n","---CHECK HALLUCINATIONS---\n","---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n","'Finished running: generate:'\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Classic Homemade Pizza Recipe**\n\n Servings: 4-6 people\n\n**Ingredients:**\n\nFor the dough:\n- 2 cups of warm water\n- 1 tablespoon of sugar\n- 1 teaspoon of active dry yeast\n- 3 tablespoons of olive oil\n- 1 teaspoon of salt\n- 4 cups of all-purpose flour\n\nFor the sauce:\n- 1 large onion, finely chopped\n- 3 cloves of garlic, minced\n- 2 cups of canned Italian tomatoes\n- 2 tablespoons of tomato paste\n- 1 teaspoon of dried oregano\n- 1 teaspoon of dried basil\n- 1 bay leaf\n- 1 tablespoon of sugar\n- Salt and pepper to taste\n\nFor the toppings:\n- 1 cup of mozzarella cheese, shredded\n- 1/2 cup of grated Parmesan cheese\n- Toppings of your choice (e.g., pepperoni, mushrooms, bell peppers, olives)\n\n**Instructions:**\n\n**Step 1: Make the Dough**\n\n1. In a large bowl, combine the warm water, sugar, and yeast. Let it sit for 5-10 minutes until the yeast is activated and foamy.\n2. Add the olive oil, salt, and 2 cups of flour to the bowl. Mix until a shaggy dough forms.\n3. Gradually add the remaining 2 cups of flour, one cup at a time, until the dough becomes smooth and elastic.\n4. Knead the dough on a floured surface for 10-12 minutes until it becomes smooth and shiny.\n5. Place the dough in a lightly oiled bowl, cover it with plastic wrap, and let it rise in a warm place for 1-2 hours until it has doubled in size.\n\n**Step 2: Prepare the Sauce**\n\n1. Heat the olive oil in a large saucepan over medium heat.\n2. Add the chopped onion and cook until it's translucent and soft, about 5 minutes.\n3. Add the minced garlic and cook for another minute.\n4. Add the canned tomatoes, tomato paste, oregano, basil, bay leaf, sugar, salt, and pepper. Stir well to combine.\n5. Bring the sauce to a boil, then reduce the heat to low and simmer for 30-40 minutes until the sauce has thickened and reduced slightly.\n6. Remove the bay leaf and let the sauce cool to room temperature.\n\n**Step 3: Assemble and Bake the Pizza**\n\n1. Preheat the oven to 450°F (230°C).\n2. Punch down the risen dough and divide it into 2-3 equal portions, depending on the size of pizza you prefer.\n3. Roll out each portion of dough into a thin circle, about 1/4 inch thick.\n4. Place the dough on a baking sheet or pizza stone that has been sprinkled with cornmeal.\n5. Spread a layer of the cooled sauce over the dough, leaving a 1/2 inch border around the edges.\n6. Sprinkle the shredded mozzarella cheese and grated Parmesan cheese over the sauce.\n7. Add your desired toppings.\n8. Bake the pizza in the preheated oven for 10-12 minutes until the crust is golden brown and the cheese is melted and bubbly.\n9. Remove the pizza from the oven and let it cool for a few minutes before slicing and serving.\n\nEnjoy your homemade pizza!"},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":[],"metadata":{"id":"VwMtfGkSsjK0"},"execution_count":null,"outputs":[]}]}